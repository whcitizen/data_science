{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Implment 'Multiply' layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AddLayer(object):\n",
    "    def forward(self,x,y):\n",
    "        z = x+y\n",
    "        return z\n",
    "    def backward(self,dz): #dz represents dL/dz propagated from the above layer\n",
    "        dx = dz #dL/dz * dz/dx\n",
    "        dy = dz #dL/dz * dz/dy\n",
    "        return [dx,dy]\n",
    "\n",
    "class MultiplyLayer(object):\n",
    "    def forward(self,x,y):\n",
    "        z = x*y\n",
    "        self.x = x  #keep activation during feed forwarding!\n",
    "        self.y = y\n",
    "        return z\n",
    "    def backward(self,dz): #dz represents dL/dz propgated from the above layer\n",
    "        dx = dz * self.y  #dL/dz * dz/dx\n",
    "        dy = dz * self.x  #dL/dz * dz/dy\n",
    "        return [dx,dy]\n",
    "    def numeric_grad(self,x,y,dz=1.0,eps=0.0001):\n",
    "        dx = (self.forward(x+eps,y) - self.forward(x-eps,y))/(2*eps) * dz\n",
    "        dy = (self.forward(x,y+eps) - self.forward(x,y-eps))/(2*eps) * dz\n",
    "        return [dx,dy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed forward operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add = AddLayer()\n",
    "mult = MultiplyLayer()\n",
    "add.forward(mult.forward(2,3),-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how backprop works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1]\n",
      "[3, 2]\n"
     ]
    }
   ],
   "source": [
    "print(add.backward(1))\n",
    "print(mult.backward(add.backward(1)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare analytical grads with numerical ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2]\n",
      "[2.9999999999999805, 1.9999999999999574]\n"
     ]
    }
   ],
   "source": [
    "print(mult.backward(dz=1))\n",
    "print(mult.numeric_grad(2,3,dz=1,eps=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: implement logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the digit dataset again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img2vector(filename):\n",
    "    returnVect = np.zeros((1,1024)) #images are 32x32, constituting 1024-dim vectors\n",
    "    fr = open(filename)\n",
    "    for i in range(32):\n",
    "        lineStr = fr.readline()\n",
    "        for j in range(32):\n",
    "            returnVect[0,32*i+j] = int(lineStr[j])\n",
    "    return returnVect\n",
    "\n",
    "def loadDigits(dataDir):\n",
    "    labels = []\n",
    "    fileList = os.listdir(dataDir)\n",
    "    m = len(fileList)\n",
    "    dataMat = np.zeros((m,1024))\n",
    "    labelMat = np.zeros((m,10))\n",
    "    for i in range(m):\n",
    "        fileNameStr = fileList[i]  #load the training set\n",
    "        fileStr = fileNameStr.split('.')[0]  #take off \".txt\"\n",
    "        classNumStr = int(fileStr.split('_')[0])\n",
    "        labelMat[i,classNumStr]=1.0\n",
    "        dataMat[i,:] = img2vector('%s/%s' % (dataDir, fileNameStr))\n",
    "    return dataMat, labelMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainMat, trainLabels = loadDigits('trainingDigits') \n",
    "testMat, testLabels = loadDigits('testDigits') \n",
    "meanVec = np.average(trainMat,axis=0)\n",
    "stdVec = np.std(trainMat,axis=0)+1.0\n",
    "trainMat = (trainMat-meanVec)/stdVec\n",
    "testMat = (testMat-meanVec)/stdVec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: implement Linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Linear(object):\n",
    "    def __init__(self,in_size,out_size):\n",
    "        self.W = np.random.uniform(size=(in_size,out_size))\n",
    "        self.b = np.random.uniform(size=(out_size))\n",
    "        self.X = None\n",
    "        self.dX = None\n",
    "        self.db = None\n",
    "    def forward(self,X):\n",
    "        self.X = X\n",
    "        return np.dot(X,self.W) + self.b  \n",
    "    def backward(self,dY):\n",
    "        dX = np.dot(dY, self.W.T)\n",
    "        self.dW = np.dot(self.X.T, dY)\n",
    "        self.db = np.sum(dY, axis=0)\n",
    "        return dX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SoftmaxCrossEnt(object):\n",
    "    def __init__(self):\n",
    "        self.Y = None\n",
    "        self.t = None\n",
    "    def forward(self,X,t):\n",
    "        expX = np.exp(X)\n",
    "        Y = expX / np.sum(expX, axis=1).reshape(-1,1)  #softmax\n",
    "        L = -np.sum(t*np.log(Y),axis=1)\n",
    "        self.Y,self.t = Y,t \n",
    "        return L\n",
    "    def backward(self,dZ=None):\n",
    "        return self.Y - self.t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's train with an SGD optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 1: Loss 4.159369\n",
      "Epoch 1, Iteration 2: Loss 4.241496\n",
      "Epoch 1, Iteration 3: Loss 3.869333\n",
      "Epoch 1, Iteration 4: Loss 4.371841\n",
      "Epoch 1, Iteration 5: Loss 4.287650\n",
      "Epoch 1, Iteration 6: Loss 4.204139\n",
      "Epoch 1, Iteration 7: Loss 3.842538\n",
      "Epoch 1, Iteration 8: Loss 4.184414\n",
      "Epoch 1, Iteration 9: Loss 4.539487\n",
      "Epoch 1, Iteration 10: Loss 4.133530\n",
      "Epoch 1, Iteration 11: Loss 4.759192\n",
      "Epoch 1, Iteration 12: Loss 4.095834\n",
      "Epoch 1, Iteration 13: Loss 4.782309\n",
      "Epoch 1, Iteration 14: Loss 4.396527\n",
      "Epoch 1, Iteration 15: Loss 4.362702\n",
      "Epoch 1, Iteration 16: Loss 4.099569\n",
      "Epoch 1, Iteration 17: Loss 4.722175\n",
      "Epoch 1, Iteration 18: Loss 5.547005\n",
      "Epoch 1, Iteration 19: Loss 4.653979\n",
      "Epoch 1, Iteration 20: Loss 3.543349\n",
      "Epoch 1, Iteration 21: Loss 4.511684\n",
      "Epoch 1, Iteration 22: Loss 4.297925\n",
      "Epoch 1, Iteration 23: Loss 3.822228\n",
      "Epoch 1, Iteration 24: Loss 4.575787\n",
      "Epoch 1, Iteration 25: Loss 4.613274\n",
      "Epoch 1, Iteration 26: Loss 4.388602\n",
      "Epoch 1, Iteration 27: Loss 3.717326\n",
      "Epoch 1, Iteration 28: Loss 4.003442\n",
      "Epoch 1, Iteration 29: Loss 3.561690\n",
      "Epoch 1, Iteration 30: Loss 3.425671\n",
      "Epoch 1, Iteration 31: Loss 4.853249\n",
      "Epoch 1, Iteration 32: Loss 3.886398\n",
      "Epoch 1, Iteration 33: Loss 3.668261\n",
      "Epoch 1, Iteration 34: Loss 3.733128\n",
      "Epoch 1, Iteration 35: Loss 3.933757\n",
      "Epoch 1, Iteration 36: Loss 3.892279\n",
      "Epoch 1, Iteration 37: Loss 4.405788\n",
      "Epoch 1, Iteration 38: Loss 3.618584\n",
      "Epoch 1, Iteration 39: Loss 3.886044\n",
      "Epoch 1, Iteration 40: Loss 4.058603\n",
      "Epoch 1, Iteration 41: Loss 4.692437\n",
      "Epoch 1, Iteration 42: Loss 3.825418\n",
      "Epoch 1, Iteration 43: Loss 4.058213\n",
      "Epoch 1, Iteration 44: Loss 4.819988\n",
      "Epoch 1, Iteration 45: Loss 4.002899\n",
      "Epoch 1, Iteration 46: Loss 4.318811\n",
      "Epoch 1, Iteration 47: Loss 4.371530\n",
      "Epoch 1, Iteration 48: Loss 3.725648\n",
      "Epoch 1, Iteration 49: Loss 4.091761\n",
      "Epoch 1, Iteration 50: Loss 3.808512\n",
      "Epoch 1, Iteration 51: Loss 4.984562\n",
      "Epoch 1, Iteration 52: Loss 3.708192\n",
      "Epoch 1, Iteration 53: Loss 3.749067\n",
      "Epoch 1, Iteration 54: Loss 3.949171\n",
      "Epoch 1, Iteration 55: Loss 3.428574\n",
      "Epoch 1, Iteration 56: Loss 3.677308\n",
      "Epoch 1, Iteration 57: Loss 3.854014\n",
      "Epoch 1, Iteration 58: Loss 3.127499\n",
      "Epoch 1, Iteration 59: Loss 3.442739\n",
      "Epoch 1, Iteration 60: Loss 3.327681\n",
      "Epoch 1, Iteration 61: Loss 4.126639\n",
      "Epoch 1, Iteration 62: Loss 3.886808\n",
      "Epoch 1, Iteration 63: Loss 3.648445\n",
      "Epoch 1, Iteration 64: Loss 3.941895\n",
      "Epoch 1, Iteration 65: Loss 3.650495\n",
      "Epoch 2, Iteration 1: Loss 3.359006\n",
      "Epoch 2, Iteration 2: Loss 3.341571\n",
      "Epoch 2, Iteration 3: Loss 3.812725\n",
      "Epoch 2, Iteration 4: Loss 3.206719\n",
      "Epoch 2, Iteration 5: Loss 3.763217\n",
      "Epoch 2, Iteration 6: Loss 4.870751\n",
      "Epoch 2, Iteration 7: Loss 3.478997\n",
      "Epoch 2, Iteration 8: Loss 2.800456\n",
      "Epoch 2, Iteration 9: Loss 4.084106\n",
      "Epoch 2, Iteration 10: Loss 3.919634\n",
      "Epoch 2, Iteration 11: Loss 4.201021\n",
      "Epoch 2, Iteration 12: Loss 3.559398\n",
      "Epoch 2, Iteration 13: Loss 2.923375\n",
      "Epoch 2, Iteration 14: Loss 4.141994\n",
      "Epoch 2, Iteration 15: Loss 4.445406\n",
      "Epoch 2, Iteration 16: Loss 3.554029\n",
      "Epoch 2, Iteration 17: Loss 4.502504\n",
      "Epoch 2, Iteration 18: Loss 4.107115\n",
      "Epoch 2, Iteration 19: Loss 3.754117\n",
      "Epoch 2, Iteration 20: Loss 4.167265\n",
      "Epoch 2, Iteration 21: Loss 3.645257\n",
      "Epoch 2, Iteration 22: Loss 3.465981\n",
      "Epoch 2, Iteration 23: Loss 3.507249\n",
      "Epoch 2, Iteration 24: Loss 3.147711\n",
      "Epoch 2, Iteration 25: Loss 3.888040\n",
      "Epoch 2, Iteration 26: Loss 3.588649\n",
      "Epoch 2, Iteration 27: Loss 3.438369\n",
      "Epoch 2, Iteration 28: Loss 3.190265\n",
      "Epoch 2, Iteration 29: Loss 4.349595\n",
      "Epoch 2, Iteration 30: Loss 3.460822\n",
      "Epoch 2, Iteration 31: Loss 2.971443\n",
      "Epoch 2, Iteration 32: Loss 4.135535\n",
      "Epoch 2, Iteration 33: Loss 3.876224\n",
      "Epoch 2, Iteration 34: Loss 3.781573\n",
      "Epoch 2, Iteration 35: Loss 3.380093\n",
      "Epoch 2, Iteration 36: Loss 3.680734\n",
      "Epoch 2, Iteration 37: Loss 3.202804\n",
      "Epoch 2, Iteration 38: Loss 3.744009\n",
      "Epoch 2, Iteration 39: Loss 3.560414\n",
      "Epoch 2, Iteration 40: Loss 3.847748\n",
      "Epoch 2, Iteration 41: Loss 4.241933\n",
      "Epoch 2, Iteration 42: Loss 3.174001\n",
      "Epoch 2, Iteration 43: Loss 3.583249\n",
      "Epoch 2, Iteration 44: Loss 3.445785\n",
      "Epoch 2, Iteration 45: Loss 3.535136\n",
      "Epoch 2, Iteration 46: Loss 3.604943\n",
      "Epoch 2, Iteration 47: Loss 3.790236\n",
      "Epoch 2, Iteration 48: Loss 4.129660\n",
      "Epoch 2, Iteration 49: Loss 3.355055\n",
      "Epoch 2, Iteration 50: Loss 4.130511\n",
      "Epoch 2, Iteration 51: Loss 3.280816\n",
      "Epoch 2, Iteration 52: Loss 3.020215\n",
      "Epoch 2, Iteration 53: Loss 3.364280\n",
      "Epoch 2, Iteration 54: Loss 3.293004\n",
      "Epoch 2, Iteration 55: Loss 4.409853\n",
      "Epoch 2, Iteration 56: Loss 4.021143\n",
      "Epoch 2, Iteration 57: Loss 3.505865\n",
      "Epoch 2, Iteration 58: Loss 3.896014\n",
      "Epoch 2, Iteration 59: Loss 4.407701\n",
      "Epoch 2, Iteration 60: Loss 3.157403\n",
      "Epoch 2, Iteration 61: Loss 3.779296\n",
      "Epoch 2, Iteration 62: Loss 3.735973\n",
      "Epoch 2, Iteration 63: Loss 3.634419\n",
      "Epoch 2, Iteration 64: Loss 3.988238\n",
      "Epoch 2, Iteration 65: Loss 2.397316\n",
      "Epoch 3, Iteration 1: Loss 2.609414\n",
      "Epoch 3, Iteration 2: Loss 3.063037\n",
      "Epoch 3, Iteration 3: Loss 3.634876\n",
      "Epoch 3, Iteration 4: Loss 3.529525\n",
      "Epoch 3, Iteration 5: Loss 2.911919\n",
      "Epoch 3, Iteration 6: Loss 3.781110\n",
      "Epoch 3, Iteration 7: Loss 3.383965\n",
      "Epoch 3, Iteration 8: Loss 3.415257\n",
      "Epoch 3, Iteration 9: Loss 4.015653\n",
      "Epoch 3, Iteration 10: Loss 2.511893\n",
      "Epoch 3, Iteration 11: Loss 3.713657\n",
      "Epoch 3, Iteration 12: Loss 3.177116\n",
      "Epoch 3, Iteration 13: Loss 3.209464\n",
      "Epoch 3, Iteration 14: Loss 3.636721\n",
      "Epoch 3, Iteration 15: Loss 3.454087\n",
      "Epoch 3, Iteration 16: Loss 3.377355\n",
      "Epoch 3, Iteration 17: Loss 3.297731\n",
      "Epoch 3, Iteration 18: Loss 4.493277\n",
      "Epoch 3, Iteration 19: Loss 3.572133\n",
      "Epoch 3, Iteration 20: Loss 2.784365\n",
      "Epoch 3, Iteration 21: Loss 3.300626\n",
      "Epoch 3, Iteration 22: Loss 3.579631\n",
      "Epoch 3, Iteration 23: Loss 3.281652\n",
      "Epoch 3, Iteration 24: Loss 3.388090\n",
      "Epoch 3, Iteration 25: Loss 3.578646\n",
      "Epoch 3, Iteration 26: Loss 3.770010\n",
      "Epoch 3, Iteration 27: Loss 2.668121\n",
      "Epoch 3, Iteration 28: Loss 2.730942\n",
      "Epoch 3, Iteration 29: Loss 3.135417\n",
      "Epoch 3, Iteration 30: Loss 3.803763\n",
      "Epoch 3, Iteration 31: Loss 3.425501\n",
      "Epoch 3, Iteration 32: Loss 3.079722\n",
      "Epoch 3, Iteration 33: Loss 2.715848\n",
      "Epoch 3, Iteration 34: Loss 3.584606\n",
      "Epoch 3, Iteration 35: Loss 3.298778\n",
      "Epoch 3, Iteration 36: Loss 2.846512\n",
      "Epoch 3, Iteration 37: Loss 3.681084\n",
      "Epoch 3, Iteration 38: Loss 2.778214\n",
      "Epoch 3, Iteration 39: Loss 3.060638\n",
      "Epoch 3, Iteration 40: Loss 3.695679\n",
      "Epoch 3, Iteration 41: Loss 3.792879\n",
      "Epoch 3, Iteration 42: Loss 3.110491\n",
      "Epoch 3, Iteration 43: Loss 3.530609\n",
      "Epoch 3, Iteration 44: Loss 3.895874\n",
      "Epoch 3, Iteration 45: Loss 3.295609\n",
      "Epoch 3, Iteration 46: Loss 2.988823\n",
      "Epoch 3, Iteration 47: Loss 3.358882\n",
      "Epoch 3, Iteration 48: Loss 3.292715\n",
      "Epoch 3, Iteration 49: Loss 3.469865\n",
      "Epoch 3, Iteration 50: Loss 4.069278\n",
      "Epoch 3, Iteration 51: Loss 3.456588\n",
      "Epoch 3, Iteration 52: Loss 3.486919\n",
      "Epoch 3, Iteration 53: Loss 3.077610\n",
      "Epoch 3, Iteration 54: Loss 3.384855\n",
      "Epoch 3, Iteration 55: Loss 3.184714\n",
      "Epoch 3, Iteration 56: Loss 3.438102\n",
      "Epoch 3, Iteration 57: Loss 3.280917\n",
      "Epoch 3, Iteration 58: Loss 3.348911\n",
      "Epoch 3, Iteration 59: Loss 2.546521\n",
      "Epoch 3, Iteration 60: Loss 3.516214\n",
      "Epoch 3, Iteration 61: Loss 2.890488\n",
      "Epoch 3, Iteration 62: Loss 2.871963\n",
      "Epoch 3, Iteration 63: Loss 3.164878\n",
      "Epoch 3, Iteration 64: Loss 3.104807\n",
      "Epoch 3, Iteration 65: Loss 3.414098\n",
      "Epoch 4, Iteration 1: Loss 3.382015\n",
      "Epoch 4, Iteration 2: Loss 2.728988\n",
      "Epoch 4, Iteration 3: Loss 2.898509\n",
      "Epoch 4, Iteration 4: Loss 2.864087\n",
      "Epoch 4, Iteration 5: Loss 3.437551\n",
      "Epoch 4, Iteration 6: Loss 3.034956\n",
      "Epoch 4, Iteration 7: Loss 2.930980\n",
      "Epoch 4, Iteration 8: Loss 3.386947\n",
      "Epoch 4, Iteration 9: Loss 3.800864\n",
      "Epoch 4, Iteration 10: Loss 2.831624\n",
      "Epoch 4, Iteration 11: Loss 3.191636\n",
      "Epoch 4, Iteration 12: Loss 3.757615\n",
      "Epoch 4, Iteration 13: Loss 3.084797\n",
      "Epoch 4, Iteration 14: Loss 2.921173\n",
      "Epoch 4, Iteration 15: Loss 2.810290\n",
      "Epoch 4, Iteration 16: Loss 2.769052\n",
      "Epoch 4, Iteration 17: Loss 3.586344\n",
      "Epoch 4, Iteration 18: Loss 3.039965\n",
      "Epoch 4, Iteration 19: Loss 3.020659\n",
      "Epoch 4, Iteration 20: Loss 2.838983\n",
      "Epoch 4, Iteration 21: Loss 2.896133\n",
      "Epoch 4, Iteration 22: Loss 3.151088\n",
      "Epoch 4, Iteration 23: Loss 3.779612\n",
      "Epoch 4, Iteration 24: Loss 3.001202\n",
      "Epoch 4, Iteration 25: Loss 3.200881\n",
      "Epoch 4, Iteration 26: Loss 2.680252\n",
      "Epoch 4, Iteration 27: Loss 3.205613\n",
      "Epoch 4, Iteration 28: Loss 3.639194\n",
      "Epoch 4, Iteration 29: Loss 3.401833\n",
      "Epoch 4, Iteration 30: Loss 2.922337\n",
      "Epoch 4, Iteration 31: Loss 3.461611\n",
      "Epoch 4, Iteration 32: Loss 2.885375\n",
      "Epoch 4, Iteration 33: Loss 2.491304\n",
      "Epoch 4, Iteration 34: Loss 3.145734\n",
      "Epoch 4, Iteration 35: Loss 2.903557\n",
      "Epoch 4, Iteration 36: Loss 3.077424\n",
      "Epoch 4, Iteration 37: Loss 2.715665\n",
      "Epoch 4, Iteration 38: Loss 2.610155\n",
      "Epoch 4, Iteration 39: Loss 2.994931\n",
      "Epoch 4, Iteration 40: Loss 3.876552\n",
      "Epoch 4, Iteration 41: Loss 2.537203\n",
      "Epoch 4, Iteration 42: Loss 2.930582\n",
      "Epoch 4, Iteration 43: Loss 2.657760\n",
      "Epoch 4, Iteration 44: Loss 2.300059\n",
      "Epoch 4, Iteration 45: Loss 2.118405\n",
      "Epoch 4, Iteration 46: Loss 3.112635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Iteration 47: Loss 3.625562\n",
      "Epoch 4, Iteration 48: Loss 1.770071\n",
      "Epoch 4, Iteration 49: Loss 2.587989\n",
      "Epoch 4, Iteration 50: Loss 2.456660\n",
      "Epoch 4, Iteration 51: Loss 3.005008\n",
      "Epoch 4, Iteration 52: Loss 3.211240\n",
      "Epoch 4, Iteration 53: Loss 2.492839\n",
      "Epoch 4, Iteration 54: Loss 2.666094\n",
      "Epoch 4, Iteration 55: Loss 2.912614\n",
      "Epoch 4, Iteration 56: Loss 2.961146\n",
      "Epoch 4, Iteration 57: Loss 2.788989\n",
      "Epoch 4, Iteration 58: Loss 3.471017\n",
      "Epoch 4, Iteration 59: Loss 3.288556\n",
      "Epoch 4, Iteration 60: Loss 3.010062\n",
      "Epoch 4, Iteration 61: Loss 2.541403\n",
      "Epoch 4, Iteration 62: Loss 2.745540\n",
      "Epoch 4, Iteration 63: Loss 3.247861\n",
      "Epoch 4, Iteration 64: Loss 3.067235\n",
      "Epoch 4, Iteration 65: Loss 3.917911\n",
      "Epoch 5, Iteration 1: Loss 3.454386\n",
      "Epoch 5, Iteration 2: Loss 3.164608\n",
      "Epoch 5, Iteration 3: Loss 2.402362\n",
      "Epoch 5, Iteration 4: Loss 2.732642\n",
      "Epoch 5, Iteration 5: Loss 3.178726\n",
      "Epoch 5, Iteration 6: Loss 2.364411\n",
      "Epoch 5, Iteration 7: Loss 3.846074\n",
      "Epoch 5, Iteration 8: Loss 1.973493\n",
      "Epoch 5, Iteration 9: Loss 3.368807\n",
      "Epoch 5, Iteration 10: Loss 2.769169\n",
      "Epoch 5, Iteration 11: Loss 2.744707\n",
      "Epoch 5, Iteration 12: Loss 3.070806\n",
      "Epoch 5, Iteration 13: Loss 2.609876\n",
      "Epoch 5, Iteration 14: Loss 2.382139\n",
      "Epoch 5, Iteration 15: Loss 3.058532\n",
      "Epoch 5, Iteration 16: Loss 2.512148\n",
      "Epoch 5, Iteration 17: Loss 2.903687\n",
      "Epoch 5, Iteration 18: Loss 2.668634\n",
      "Epoch 5, Iteration 19: Loss 3.425562\n",
      "Epoch 5, Iteration 20: Loss 3.374101\n",
      "Epoch 5, Iteration 21: Loss 2.478848\n",
      "Epoch 5, Iteration 22: Loss 2.925521\n",
      "Epoch 5, Iteration 23: Loss 2.962423\n",
      "Epoch 5, Iteration 24: Loss 2.283870\n",
      "Epoch 5, Iteration 25: Loss 2.727229\n",
      "Epoch 5, Iteration 26: Loss 2.223354\n",
      "Epoch 5, Iteration 27: Loss 3.535170\n",
      "Epoch 5, Iteration 28: Loss 1.921084\n",
      "Epoch 5, Iteration 29: Loss 2.425588\n",
      "Epoch 5, Iteration 30: Loss 3.181477\n",
      "Epoch 5, Iteration 31: Loss 2.407650\n",
      "Epoch 5, Iteration 32: Loss 3.129303\n",
      "Epoch 5, Iteration 33: Loss 3.047750\n",
      "Epoch 5, Iteration 34: Loss 2.616200\n",
      "Epoch 5, Iteration 35: Loss 3.159915\n",
      "Epoch 5, Iteration 36: Loss 2.432184\n",
      "Epoch 5, Iteration 37: Loss 2.461223\n",
      "Epoch 5, Iteration 38: Loss 2.381018\n",
      "Epoch 5, Iteration 39: Loss 2.576314\n",
      "Epoch 5, Iteration 40: Loss 2.203013\n",
      "Epoch 5, Iteration 41: Loss 2.669102\n",
      "Epoch 5, Iteration 42: Loss 2.647726\n",
      "Epoch 5, Iteration 43: Loss 2.439334\n",
      "Epoch 5, Iteration 44: Loss 2.814999\n",
      "Epoch 5, Iteration 45: Loss 2.492181\n",
      "Epoch 5, Iteration 46: Loss 1.612397\n",
      "Epoch 5, Iteration 47: Loss 2.322802\n",
      "Epoch 5, Iteration 48: Loss 3.405098\n",
      "Epoch 5, Iteration 49: Loss 2.920329\n",
      "Epoch 5, Iteration 50: Loss 3.172789\n",
      "Epoch 5, Iteration 51: Loss 2.691405\n",
      "Epoch 5, Iteration 52: Loss 2.219185\n",
      "Epoch 5, Iteration 53: Loss 3.014991\n",
      "Epoch 5, Iteration 54: Loss 2.689288\n",
      "Epoch 5, Iteration 55: Loss 2.811525\n",
      "Epoch 5, Iteration 56: Loss 2.059996\n",
      "Epoch 5, Iteration 57: Loss 2.883317\n",
      "Epoch 5, Iteration 58: Loss 2.675821\n",
      "Epoch 5, Iteration 59: Loss 2.792428\n",
      "Epoch 5, Iteration 60: Loss 2.874716\n",
      "Epoch 5, Iteration 61: Loss 2.621513\n",
      "Epoch 5, Iteration 62: Loss 2.632756\n",
      "Epoch 5, Iteration 63: Loss 2.463453\n",
      "Epoch 5, Iteration 64: Loss 2.368965\n",
      "Epoch 5, Iteration 65: Loss 3.126944\n",
      "Epoch 6, Iteration 1: Loss 2.615572\n",
      "Epoch 6, Iteration 2: Loss 2.498126\n",
      "Epoch 6, Iteration 3: Loss 2.476555\n",
      "Epoch 6, Iteration 4: Loss 2.886063\n",
      "Epoch 6, Iteration 5: Loss 2.982888\n",
      "Epoch 6, Iteration 6: Loss 2.153036\n",
      "Epoch 6, Iteration 7: Loss 2.134415\n",
      "Epoch 6, Iteration 8: Loss 2.592617\n",
      "Epoch 6, Iteration 9: Loss 2.822113\n",
      "Epoch 6, Iteration 10: Loss 3.232138\n",
      "Epoch 6, Iteration 11: Loss 2.417060\n",
      "Epoch 6, Iteration 12: Loss 2.985826\n",
      "Epoch 6, Iteration 13: Loss 2.873036\n",
      "Epoch 6, Iteration 14: Loss 2.659611\n",
      "Epoch 6, Iteration 15: Loss 2.168106\n",
      "Epoch 6, Iteration 16: Loss 2.872232\n",
      "Epoch 6, Iteration 17: Loss 2.247715\n",
      "Epoch 6, Iteration 18: Loss 2.719581\n",
      "Epoch 6, Iteration 19: Loss 2.321841\n",
      "Epoch 6, Iteration 20: Loss 1.909084\n",
      "Epoch 6, Iteration 21: Loss 2.086558\n",
      "Epoch 6, Iteration 22: Loss 2.738296\n",
      "Epoch 6, Iteration 23: Loss 1.954900\n",
      "Epoch 6, Iteration 24: Loss 2.433498\n",
      "Epoch 6, Iteration 25: Loss 2.872281\n",
      "Epoch 6, Iteration 26: Loss 2.420800\n",
      "Epoch 6, Iteration 27: Loss 3.174585\n",
      "Epoch 6, Iteration 28: Loss 2.154311\n",
      "Epoch 6, Iteration 29: Loss 2.054240\n",
      "Epoch 6, Iteration 30: Loss 2.573484\n",
      "Epoch 6, Iteration 31: Loss 2.650404\n",
      "Epoch 6, Iteration 32: Loss 2.579842\n",
      "Epoch 6, Iteration 33: Loss 2.146292\n",
      "Epoch 6, Iteration 34: Loss 2.186674\n",
      "Epoch 6, Iteration 35: Loss 2.248599\n",
      "Epoch 6, Iteration 36: Loss 2.335178\n",
      "Epoch 6, Iteration 37: Loss 2.387167\n",
      "Epoch 6, Iteration 38: Loss 2.689348\n",
      "Epoch 6, Iteration 39: Loss 2.652971\n",
      "Epoch 6, Iteration 40: Loss 2.500778\n",
      "Epoch 6, Iteration 41: Loss 2.776057\n",
      "Epoch 6, Iteration 42: Loss 2.470369\n",
      "Epoch 6, Iteration 43: Loss 2.246405\n",
      "Epoch 6, Iteration 44: Loss 2.022715\n",
      "Epoch 6, Iteration 45: Loss 1.915030\n",
      "Epoch 6, Iteration 46: Loss 2.216823\n",
      "Epoch 6, Iteration 47: Loss 2.474359\n",
      "Epoch 6, Iteration 48: Loss 1.895479\n",
      "Epoch 6, Iteration 49: Loss 2.127733\n",
      "Epoch 6, Iteration 50: Loss 2.046383\n",
      "Epoch 6, Iteration 51: Loss 2.446907\n",
      "Epoch 6, Iteration 52: Loss 2.835854\n",
      "Epoch 6, Iteration 53: Loss 2.986428\n",
      "Epoch 6, Iteration 54: Loss 2.420471\n",
      "Epoch 6, Iteration 55: Loss 2.440955\n",
      "Epoch 6, Iteration 56: Loss 2.316260\n",
      "Epoch 6, Iteration 57: Loss 3.099601\n",
      "Epoch 6, Iteration 58: Loss 2.552490\n",
      "Epoch 6, Iteration 59: Loss 2.367893\n",
      "Epoch 6, Iteration 60: Loss 2.424586\n",
      "Epoch 6, Iteration 61: Loss 2.779336\n",
      "Epoch 6, Iteration 62: Loss 2.186158\n",
      "Epoch 6, Iteration 63: Loss 2.644710\n",
      "Epoch 6, Iteration 64: Loss 2.931815\n",
      "Epoch 6, Iteration 65: Loss 2.548870\n",
      "Epoch 7, Iteration 1: Loss 2.146328\n",
      "Epoch 7, Iteration 2: Loss 2.669572\n",
      "Epoch 7, Iteration 3: Loss 2.342590\n",
      "Epoch 7, Iteration 4: Loss 2.453654\n",
      "Epoch 7, Iteration 5: Loss 1.999707\n",
      "Epoch 7, Iteration 6: Loss 2.281506\n",
      "Epoch 7, Iteration 7: Loss 1.784521\n",
      "Epoch 7, Iteration 8: Loss 1.752119\n",
      "Epoch 7, Iteration 9: Loss 2.470860\n",
      "Epoch 7, Iteration 10: Loss 2.546513\n",
      "Epoch 7, Iteration 11: Loss 2.341648\n",
      "Epoch 7, Iteration 12: Loss 2.261566\n",
      "Epoch 7, Iteration 13: Loss 3.009563\n",
      "Epoch 7, Iteration 14: Loss 2.150738\n",
      "Epoch 7, Iteration 15: Loss 2.255598\n",
      "Epoch 7, Iteration 16: Loss 1.591578\n",
      "Epoch 7, Iteration 17: Loss 2.364844\n",
      "Epoch 7, Iteration 18: Loss 2.074047\n",
      "Epoch 7, Iteration 19: Loss 2.064137\n",
      "Epoch 7, Iteration 20: Loss 2.202299\n",
      "Epoch 7, Iteration 21: Loss 2.248703\n",
      "Epoch 7, Iteration 22: Loss 2.642520\n",
      "Epoch 7, Iteration 23: Loss 2.406410\n",
      "Epoch 7, Iteration 24: Loss 2.519236\n",
      "Epoch 7, Iteration 25: Loss 2.869841\n",
      "Epoch 7, Iteration 26: Loss 2.038002\n",
      "Epoch 7, Iteration 27: Loss 2.133986\n",
      "Epoch 7, Iteration 28: Loss 2.319906\n",
      "Epoch 7, Iteration 29: Loss 2.989291\n",
      "Epoch 7, Iteration 30: Loss 2.148573\n",
      "Epoch 7, Iteration 31: Loss 2.412319\n",
      "Epoch 7, Iteration 32: Loss 2.614233\n",
      "Epoch 7, Iteration 33: Loss 2.187266\n",
      "Epoch 7, Iteration 34: Loss 2.139816\n",
      "Epoch 7, Iteration 35: Loss 2.310493\n",
      "Epoch 7, Iteration 36: Loss 2.300852\n",
      "Epoch 7, Iteration 37: Loss 2.200017\n",
      "Epoch 7, Iteration 38: Loss 2.667885\n",
      "Epoch 7, Iteration 39: Loss 1.838635\n",
      "Epoch 7, Iteration 40: Loss 2.402656\n",
      "Epoch 7, Iteration 41: Loss 2.342774\n",
      "Epoch 7, Iteration 42: Loss 2.176623\n",
      "Epoch 7, Iteration 43: Loss 2.572590\n",
      "Epoch 7, Iteration 44: Loss 2.469804\n",
      "Epoch 7, Iteration 45: Loss 2.054412\n",
      "Epoch 7, Iteration 46: Loss 2.413507\n",
      "Epoch 7, Iteration 47: Loss 1.918244\n",
      "Epoch 7, Iteration 48: Loss 2.169833\n",
      "Epoch 7, Iteration 49: Loss 1.803032\n",
      "Epoch 7, Iteration 50: Loss 1.815153\n",
      "Epoch 7, Iteration 51: Loss 2.320827\n",
      "Epoch 7, Iteration 52: Loss 2.051558\n",
      "Epoch 7, Iteration 53: Loss 2.362683\n",
      "Epoch 7, Iteration 54: Loss 2.019106\n",
      "Epoch 7, Iteration 55: Loss 2.555079\n",
      "Epoch 7, Iteration 56: Loss 2.372480\n",
      "Epoch 7, Iteration 57: Loss 2.283654\n",
      "Epoch 7, Iteration 58: Loss 1.607003\n",
      "Epoch 7, Iteration 59: Loss 2.422678\n",
      "Epoch 7, Iteration 60: Loss 1.974477\n",
      "Epoch 7, Iteration 61: Loss 2.625918\n",
      "Epoch 7, Iteration 62: Loss 2.210441\n",
      "Epoch 7, Iteration 63: Loss 2.446869\n",
      "Epoch 7, Iteration 64: Loss 2.033677\n",
      "Epoch 7, Iteration 65: Loss 2.924544\n",
      "Epoch 8, Iteration 1: Loss 2.113363\n",
      "Epoch 8, Iteration 2: Loss 2.469736\n",
      "Epoch 8, Iteration 3: Loss 1.702964\n",
      "Epoch 8, Iteration 4: Loss 2.068913\n",
      "Epoch 8, Iteration 5: Loss 1.886023\n",
      "Epoch 8, Iteration 6: Loss 3.072724\n",
      "Epoch 8, Iteration 7: Loss 2.522221\n",
      "Epoch 8, Iteration 8: Loss 2.613343\n",
      "Epoch 8, Iteration 9: Loss 1.762009\n",
      "Epoch 8, Iteration 10: Loss 2.180577\n",
      "Epoch 8, Iteration 11: Loss 2.268213\n",
      "Epoch 8, Iteration 12: Loss 2.409910\n",
      "Epoch 8, Iteration 13: Loss 2.175796\n",
      "Epoch 8, Iteration 14: Loss 2.220280\n",
      "Epoch 8, Iteration 15: Loss 2.095793\n",
      "Epoch 8, Iteration 16: Loss 2.155832\n",
      "Epoch 8, Iteration 17: Loss 1.735887\n",
      "Epoch 8, Iteration 18: Loss 2.017750\n",
      "Epoch 8, Iteration 19: Loss 1.743458\n",
      "Epoch 8, Iteration 20: Loss 1.680730\n",
      "Epoch 8, Iteration 21: Loss 2.593656\n",
      "Epoch 8, Iteration 22: Loss 2.498495\n",
      "Epoch 8, Iteration 23: Loss 2.534903\n",
      "Epoch 8, Iteration 24: Loss 1.901990\n",
      "Epoch 8, Iteration 25: Loss 2.061361\n",
      "Epoch 8, Iteration 26: Loss 1.740798\n",
      "Epoch 8, Iteration 27: Loss 2.322533\n",
      "Epoch 8, Iteration 28: Loss 1.848119\n",
      "Epoch 8, Iteration 29: Loss 2.490542\n",
      "Epoch 8, Iteration 30: Loss 1.945033\n",
      "Epoch 8, Iteration 31: Loss 2.385167\n",
      "Epoch 8, Iteration 32: Loss 2.093100\n",
      "Epoch 8, Iteration 33: Loss 2.561356\n",
      "Epoch 8, Iteration 34: Loss 2.306418\n",
      "Epoch 8, Iteration 35: Loss 2.004082\n",
      "Epoch 8, Iteration 36: Loss 2.172406\n",
      "Epoch 8, Iteration 37: Loss 1.996780\n",
      "Epoch 8, Iteration 38: Loss 1.890445\n",
      "Epoch 8, Iteration 39: Loss 1.885051\n",
      "Epoch 8, Iteration 40: Loss 2.003007\n",
      "Epoch 8, Iteration 41: Loss 1.357349\n",
      "Epoch 8, Iteration 42: Loss 1.461968\n",
      "Epoch 8, Iteration 43: Loss 2.135052\n",
      "Epoch 8, Iteration 44: Loss 1.814801\n",
      "Epoch 8, Iteration 45: Loss 1.816314\n",
      "Epoch 8, Iteration 46: Loss 2.056965\n",
      "Epoch 8, Iteration 47: Loss 2.006601\n",
      "Epoch 8, Iteration 48: Loss 2.161439\n",
      "Epoch 8, Iteration 49: Loss 1.715000\n",
      "Epoch 8, Iteration 50: Loss 2.564553\n",
      "Epoch 8, Iteration 51: Loss 2.028483\n",
      "Epoch 8, Iteration 52: Loss 1.855660\n",
      "Epoch 8, Iteration 53: Loss 1.765293\n",
      "Epoch 8, Iteration 54: Loss 2.555053\n",
      "Epoch 8, Iteration 55: Loss 2.126529\n",
      "Epoch 8, Iteration 56: Loss 1.946640\n",
      "Epoch 8, Iteration 57: Loss 2.651964\n",
      "Epoch 8, Iteration 58: Loss 2.128458\n",
      "Epoch 8, Iteration 59: Loss 1.996426\n",
      "Epoch 8, Iteration 60: Loss 2.485411\n",
      "Epoch 8, Iteration 61: Loss 1.970497\n",
      "Epoch 8, Iteration 62: Loss 1.376155\n",
      "Epoch 8, Iteration 63: Loss 1.522508\n",
      "Epoch 8, Iteration 64: Loss 2.003520\n",
      "Epoch 8, Iteration 65: Loss 1.910254\n",
      "Epoch 9, Iteration 1: Loss 2.245310\n",
      "Epoch 9, Iteration 2: Loss 1.869727\n",
      "Epoch 9, Iteration 3: Loss 1.443618\n",
      "Epoch 9, Iteration 4: Loss 1.652991\n",
      "Epoch 9, Iteration 5: Loss 2.191609\n",
      "Epoch 9, Iteration 6: Loss 2.439046\n",
      "Epoch 9, Iteration 7: Loss 2.415309\n",
      "Epoch 9, Iteration 8: Loss 2.311671\n",
      "Epoch 9, Iteration 9: Loss 2.134167\n",
      "Epoch 9, Iteration 10: Loss 1.870043\n",
      "Epoch 9, Iteration 11: Loss 1.987581\n",
      "Epoch 9, Iteration 12: Loss 2.474848\n",
      "Epoch 9, Iteration 13: Loss 2.128527\n",
      "Epoch 9, Iteration 14: Loss 1.718546\n",
      "Epoch 9, Iteration 15: Loss 1.902952\n",
      "Epoch 9, Iteration 16: Loss 1.620291\n",
      "Epoch 9, Iteration 17: Loss 1.819898\n",
      "Epoch 9, Iteration 18: Loss 1.659590\n",
      "Epoch 9, Iteration 19: Loss 2.027713\n",
      "Epoch 9, Iteration 20: Loss 1.471752\n",
      "Epoch 9, Iteration 21: Loss 1.932659\n",
      "Epoch 9, Iteration 22: Loss 1.884227\n",
      "Epoch 9, Iteration 23: Loss 1.501397\n",
      "Epoch 9, Iteration 24: Loss 2.398913\n",
      "Epoch 9, Iteration 25: Loss 2.015296\n",
      "Epoch 9, Iteration 26: Loss 2.020251\n",
      "Epoch 9, Iteration 27: Loss 1.604701\n",
      "Epoch 9, Iteration 28: Loss 2.995404\n",
      "Epoch 9, Iteration 29: Loss 1.871169\n",
      "Epoch 9, Iteration 30: Loss 1.832233\n",
      "Epoch 9, Iteration 31: Loss 2.100107\n",
      "Epoch 9, Iteration 32: Loss 1.851324\n",
      "Epoch 9, Iteration 33: Loss 2.265114\n",
      "Epoch 9, Iteration 34: Loss 2.062002\n",
      "Epoch 9, Iteration 35: Loss 1.638806\n",
      "Epoch 9, Iteration 36: Loss 1.635335\n",
      "Epoch 9, Iteration 37: Loss 2.208419\n",
      "Epoch 9, Iteration 38: Loss 2.406633\n",
      "Epoch 9, Iteration 39: Loss 2.185534\n",
      "Epoch 9, Iteration 40: Loss 1.779002\n",
      "Epoch 9, Iteration 41: Loss 2.040569\n",
      "Epoch 9, Iteration 42: Loss 1.750579\n",
      "Epoch 9, Iteration 43: Loss 1.714071\n",
      "Epoch 9, Iteration 44: Loss 1.616337\n",
      "Epoch 9, Iteration 45: Loss 1.680523\n",
      "Epoch 9, Iteration 46: Loss 1.716901\n",
      "Epoch 9, Iteration 47: Loss 1.955313\n",
      "Epoch 9, Iteration 48: Loss 1.755878\n",
      "Epoch 9, Iteration 49: Loss 2.211294\n",
      "Epoch 9, Iteration 50: Loss 2.522561\n",
      "Epoch 9, Iteration 51: Loss 1.481342\n",
      "Epoch 9, Iteration 52: Loss 1.416220\n",
      "Epoch 9, Iteration 53: Loss 1.709501\n",
      "Epoch 9, Iteration 54: Loss 2.218224\n",
      "Epoch 9, Iteration 55: Loss 1.512880\n",
      "Epoch 9, Iteration 56: Loss 1.875112\n",
      "Epoch 9, Iteration 57: Loss 1.602135\n",
      "Epoch 9, Iteration 58: Loss 2.606352\n",
      "Epoch 9, Iteration 59: Loss 1.714188\n",
      "Epoch 9, Iteration 60: Loss 1.642084\n",
      "Epoch 9, Iteration 61: Loss 1.851481\n",
      "Epoch 9, Iteration 62: Loss 1.706359\n",
      "Epoch 9, Iteration 63: Loss 1.390262\n",
      "Epoch 9, Iteration 64: Loss 1.748537\n",
      "Epoch 9, Iteration 65: Loss 1.995443\n",
      "Epoch 10, Iteration 1: Loss 1.611989\n",
      "Epoch 10, Iteration 2: Loss 1.791923\n",
      "Epoch 10, Iteration 3: Loss 1.542746\n",
      "Epoch 10, Iteration 4: Loss 1.747835\n",
      "Epoch 10, Iteration 5: Loss 1.611378\n",
      "Epoch 10, Iteration 6: Loss 1.752606\n",
      "Epoch 10, Iteration 7: Loss 2.232277\n",
      "Epoch 10, Iteration 8: Loss 1.855861\n",
      "Epoch 10, Iteration 9: Loss 1.601450\n",
      "Epoch 10, Iteration 10: Loss 1.718152\n",
      "Epoch 10, Iteration 11: Loss 1.610508\n",
      "Epoch 10, Iteration 12: Loss 1.611609\n",
      "Epoch 10, Iteration 13: Loss 1.472369\n",
      "Epoch 10, Iteration 14: Loss 1.992699\n",
      "Epoch 10, Iteration 15: Loss 2.058220\n",
      "Epoch 10, Iteration 16: Loss 1.481215\n",
      "Epoch 10, Iteration 17: Loss 2.196436\n",
      "Epoch 10, Iteration 18: Loss 1.823373\n",
      "Epoch 10, Iteration 19: Loss 1.514764\n",
      "Epoch 10, Iteration 20: Loss 1.336861\n",
      "Epoch 10, Iteration 21: Loss 1.765830\n",
      "Epoch 10, Iteration 22: Loss 2.260494\n",
      "Epoch 10, Iteration 23: Loss 2.371718\n",
      "Epoch 10, Iteration 24: Loss 2.517757\n",
      "Epoch 10, Iteration 25: Loss 1.845741\n",
      "Epoch 10, Iteration 26: Loss 1.743975\n",
      "Epoch 10, Iteration 27: Loss 1.581233\n",
      "Epoch 10, Iteration 28: Loss 2.048827\n",
      "Epoch 10, Iteration 29: Loss 2.100156\n",
      "Epoch 10, Iteration 30: Loss 1.390511\n",
      "Epoch 10, Iteration 31: Loss 1.381845\n",
      "Epoch 10, Iteration 32: Loss 1.919443\n",
      "Epoch 10, Iteration 33: Loss 1.678771\n",
      "Epoch 10, Iteration 34: Loss 2.527028\n",
      "Epoch 10, Iteration 35: Loss 1.341095\n",
      "Epoch 10, Iteration 36: Loss 1.310131\n",
      "Epoch 10, Iteration 37: Loss 2.341465\n",
      "Epoch 10, Iteration 38: Loss 2.272943\n",
      "Epoch 10, Iteration 39: Loss 2.210096\n",
      "Epoch 10, Iteration 40: Loss 1.543857\n",
      "Epoch 10, Iteration 41: Loss 1.413422\n",
      "Epoch 10, Iteration 42: Loss 1.816475\n",
      "Epoch 10, Iteration 43: Loss 1.683430\n",
      "Epoch 10, Iteration 44: Loss 1.671808\n",
      "Epoch 10, Iteration 45: Loss 1.815070\n",
      "Epoch 10, Iteration 46: Loss 1.765626\n",
      "Epoch 10, Iteration 47: Loss 1.708799\n",
      "Epoch 10, Iteration 48: Loss 2.415224\n",
      "Epoch 10, Iteration 49: Loss 2.166932\n",
      "Epoch 10, Iteration 50: Loss 1.798496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Iteration 51: Loss 1.796119\n",
      "Epoch 10, Iteration 52: Loss 1.462009\n",
      "Epoch 10, Iteration 53: Loss 1.715597\n",
      "Epoch 10, Iteration 54: Loss 1.232431\n",
      "Epoch 10, Iteration 55: Loss 1.543254\n",
      "Epoch 10, Iteration 56: Loss 1.232938\n",
      "Epoch 10, Iteration 57: Loss 2.240966\n",
      "Epoch 10, Iteration 58: Loss 1.255948\n",
      "Epoch 10, Iteration 59: Loss 1.650053\n",
      "Epoch 10, Iteration 60: Loss 1.786854\n",
      "Epoch 10, Iteration 61: Loss 2.135444\n",
      "Epoch 10, Iteration 62: Loss 1.308016\n",
      "Epoch 10, Iteration 63: Loss 1.654336\n",
      "Epoch 10, Iteration 64: Loss 1.863353\n",
      "Epoch 10, Iteration 65: Loss 1.577022\n"
     ]
    }
   ],
   "source": [
    "nsample = trainMat.shape[0]  #sample size\n",
    "bsize=30 #batch size\n",
    "niter = int(np.ceil(nsample/bsize)) #iteration per epoch\n",
    "max_epoch=10\n",
    "alpha = 0.0001 #learning rate\n",
    "\n",
    "L1 = Linear(1024,10)\n",
    "Loss = SoftmaxCrossEnt()\n",
    "\n",
    "for e in range(max_epoch):\n",
    "    rind = np.random.permutation(nsample) #shuffle data (this is important!)\n",
    "    trainMat = trainMat[rind]\n",
    "    trainLabels = trainLabels[rind]\n",
    "    for i in range(niter):\n",
    "        X = trainMat[i*bsize:(i+1)*bsize,:]\n",
    "        t = trainLabels[i*bsize:(i+1)*bsize]        \n",
    "        L = np.average(Loss.forward(L1.forward(X),t),axis=0)\n",
    "        \n",
    "        L1.backward(Loss.backward())\n",
    "        L1.W = L1.W - alpha*L1.dW\n",
    "        L1.b = L1.b - alpha*L1.db      \n",
    "        print(\"Epoch %d, Iteration %d: Loss %f\" % (e+1, i+1, L))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: implement 3-layer perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: implement sigmoid activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Sigmoid(object):\n",
    "    def __init__(self):\n",
    "        self.Y = None\n",
    "    def forward(self,X):\n",
    "        self.Y = 1 / (1 + np.exp(-X))\n",
    "        return self.Y  \n",
    "    def backward(self,dY):\n",
    "        dX = dY * (1.0 - self.Y)*self.Y\n",
    "        return dX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: implement the network and solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 1: Loss 2.790536\n",
      "Epoch 1, Iteration 2: Loss 2.782389\n",
      "Epoch 1, Iteration 3: Loss 3.645079\n",
      "Epoch 1, Iteration 4: Loss 3.015634\n",
      "Epoch 1, Iteration 5: Loss 2.603374\n",
      "Epoch 1, Iteration 6: Loss 2.934077\n",
      "Epoch 1, Iteration 7: Loss 2.878302\n",
      "Epoch 1, Iteration 8: Loss 2.716823\n",
      "Epoch 1, Iteration 9: Loss 2.808855\n",
      "Epoch 1, Iteration 10: Loss 2.523588\n",
      "Epoch 1, Iteration 11: Loss 2.299271\n",
      "Epoch 1, Iteration 12: Loss 2.552672\n",
      "Epoch 1, Iteration 13: Loss 2.729319\n",
      "Epoch 1, Iteration 14: Loss 2.387571\n",
      "Epoch 1, Iteration 15: Loss 2.416777\n",
      "Epoch 1, Iteration 16: Loss 2.417146\n",
      "Epoch 1, Iteration 17: Loss 2.445489\n",
      "Epoch 1, Iteration 18: Loss 2.246107\n",
      "Epoch 1, Iteration 19: Loss 2.453499\n",
      "Epoch 1, Iteration 20: Loss 2.489318\n",
      "Epoch 1, Iteration 21: Loss 2.328210\n",
      "Epoch 1, Iteration 22: Loss 2.433568\n",
      "Epoch 1, Iteration 23: Loss 2.631105\n",
      "Epoch 1, Iteration 24: Loss 2.462755\n",
      "Epoch 1, Iteration 25: Loss 2.546251\n",
      "Epoch 1, Iteration 26: Loss 2.385079\n",
      "Epoch 1, Iteration 27: Loss 2.176079\n",
      "Epoch 1, Iteration 28: Loss 2.142422\n",
      "Epoch 1, Iteration 29: Loss 2.568561\n",
      "Epoch 1, Iteration 30: Loss 2.385117\n",
      "Epoch 1, Iteration 31: Loss 2.460215\n",
      "Epoch 1, Iteration 32: Loss 2.578512\n",
      "Epoch 1, Iteration 33: Loss 2.367284\n",
      "Epoch 1, Iteration 34: Loss 2.384704\n",
      "Epoch 1, Iteration 35: Loss 2.453391\n",
      "Epoch 1, Iteration 36: Loss 2.392938\n",
      "Epoch 1, Iteration 37: Loss 2.502915\n",
      "Epoch 1, Iteration 38: Loss 2.370654\n",
      "Epoch 1, Iteration 39: Loss 2.440464\n",
      "Epoch 1, Iteration 40: Loss 2.506021\n",
      "Epoch 1, Iteration 41: Loss 2.317224\n",
      "Epoch 1, Iteration 42: Loss 2.230454\n",
      "Epoch 1, Iteration 43: Loss 2.238105\n",
      "Epoch 1, Iteration 44: Loss 2.268084\n",
      "Epoch 1, Iteration 45: Loss 2.273131\n",
      "Epoch 1, Iteration 46: Loss 2.250427\n",
      "Epoch 1, Iteration 47: Loss 2.365894\n",
      "Epoch 1, Iteration 48: Loss 2.258900\n",
      "Epoch 1, Iteration 49: Loss 2.426734\n",
      "Epoch 1, Iteration 50: Loss 2.311096\n",
      "Epoch 1, Iteration 51: Loss 2.358834\n",
      "Epoch 1, Iteration 52: Loss 2.225218\n",
      "Epoch 1, Iteration 53: Loss 2.182339\n",
      "Epoch 1, Iteration 54: Loss 2.406106\n",
      "Epoch 1, Iteration 55: Loss 2.245553\n",
      "Epoch 1, Iteration 56: Loss 2.184277\n",
      "Epoch 1, Iteration 57: Loss 2.371867\n",
      "Epoch 1, Iteration 58: Loss 2.252324\n",
      "Epoch 1, Iteration 59: Loss 2.382332\n",
      "Epoch 1, Iteration 60: Loss 2.508522\n",
      "Epoch 1, Iteration 61: Loss 2.244890\n",
      "Epoch 1, Iteration 62: Loss 2.288661\n",
      "Epoch 1, Iteration 63: Loss 2.310762\n",
      "Epoch 1, Iteration 64: Loss 2.194289\n",
      "Epoch 1, Iteration 65: Loss 2.204977\n",
      "Epoch 2, Iteration 1: Loss 2.267700\n",
      "Epoch 2, Iteration 2: Loss 2.385704\n",
      "Epoch 2, Iteration 3: Loss 2.353653\n",
      "Epoch 2, Iteration 4: Loss 2.362841\n",
      "Epoch 2, Iteration 5: Loss 2.347369\n",
      "Epoch 2, Iteration 6: Loss 2.178744\n",
      "Epoch 2, Iteration 7: Loss 2.263722\n",
      "Epoch 2, Iteration 8: Loss 2.249284\n",
      "Epoch 2, Iteration 9: Loss 2.436027\n",
      "Epoch 2, Iteration 10: Loss 2.477996\n",
      "Epoch 2, Iteration 11: Loss 2.422684\n",
      "Epoch 2, Iteration 12: Loss 2.333529\n",
      "Epoch 2, Iteration 13: Loss 2.316096\n",
      "Epoch 2, Iteration 14: Loss 2.190125\n",
      "Epoch 2, Iteration 15: Loss 2.159998\n",
      "Epoch 2, Iteration 16: Loss 2.197620\n",
      "Epoch 2, Iteration 17: Loss 2.197616\n",
      "Epoch 2, Iteration 18: Loss 2.263435\n",
      "Epoch 2, Iteration 19: Loss 2.353272\n",
      "Epoch 2, Iteration 20: Loss 2.215560\n",
      "Epoch 2, Iteration 21: Loss 2.276534\n",
      "Epoch 2, Iteration 22: Loss 2.329576\n",
      "Epoch 2, Iteration 23: Loss 2.404417\n",
      "Epoch 2, Iteration 24: Loss 2.332277\n",
      "Epoch 2, Iteration 25: Loss 2.384701\n",
      "Epoch 2, Iteration 26: Loss 2.195921\n",
      "Epoch 2, Iteration 27: Loss 2.268740\n",
      "Epoch 2, Iteration 28: Loss 2.342870\n",
      "Epoch 2, Iteration 29: Loss 2.144711\n",
      "Epoch 2, Iteration 30: Loss 2.281357\n",
      "Epoch 2, Iteration 31: Loss 2.204184\n",
      "Epoch 2, Iteration 32: Loss 2.270309\n",
      "Epoch 2, Iteration 33: Loss 2.306916\n",
      "Epoch 2, Iteration 34: Loss 2.424671\n",
      "Epoch 2, Iteration 35: Loss 2.152859\n",
      "Epoch 2, Iteration 36: Loss 2.289746\n",
      "Epoch 2, Iteration 37: Loss 2.175481\n",
      "Epoch 2, Iteration 38: Loss 2.295366\n",
      "Epoch 2, Iteration 39: Loss 2.375330\n",
      "Epoch 2, Iteration 40: Loss 2.289095\n",
      "Epoch 2, Iteration 41: Loss 2.188896\n",
      "Epoch 2, Iteration 42: Loss 2.147415\n",
      "Epoch 2, Iteration 43: Loss 2.256809\n",
      "Epoch 2, Iteration 44: Loss 2.256326\n",
      "Epoch 2, Iteration 45: Loss 2.236252\n",
      "Epoch 2, Iteration 46: Loss 2.429333\n",
      "Epoch 2, Iteration 47: Loss 2.039803\n",
      "Epoch 2, Iteration 48: Loss 2.190065\n",
      "Epoch 2, Iteration 49: Loss 2.516028\n",
      "Epoch 2, Iteration 50: Loss 2.339887\n",
      "Epoch 2, Iteration 51: Loss 2.414437\n",
      "Epoch 2, Iteration 52: Loss 2.265311\n",
      "Epoch 2, Iteration 53: Loss 2.084739\n",
      "Epoch 2, Iteration 54: Loss 2.106253\n",
      "Epoch 2, Iteration 55: Loss 2.291156\n",
      "Epoch 2, Iteration 56: Loss 2.131358\n",
      "Epoch 2, Iteration 57: Loss 2.255656\n",
      "Epoch 2, Iteration 58: Loss 2.372879\n",
      "Epoch 2, Iteration 59: Loss 2.267825\n",
      "Epoch 2, Iteration 60: Loss 2.248581\n",
      "Epoch 2, Iteration 61: Loss 2.266251\n",
      "Epoch 2, Iteration 62: Loss 2.351791\n",
      "Epoch 2, Iteration 63: Loss 2.314553\n",
      "Epoch 2, Iteration 64: Loss 2.277502\n",
      "Epoch 2, Iteration 65: Loss 2.289642\n",
      "Epoch 3, Iteration 1: Loss 2.245725\n",
      "Epoch 3, Iteration 2: Loss 2.282517\n",
      "Epoch 3, Iteration 3: Loss 2.199304\n",
      "Epoch 3, Iteration 4: Loss 2.375982\n",
      "Epoch 3, Iteration 5: Loss 2.311635\n",
      "Epoch 3, Iteration 6: Loss 2.237728\n",
      "Epoch 3, Iteration 7: Loss 2.225798\n",
      "Epoch 3, Iteration 8: Loss 2.177768\n",
      "Epoch 3, Iteration 9: Loss 2.228162\n",
      "Epoch 3, Iteration 10: Loss 2.314565\n",
      "Epoch 3, Iteration 11: Loss 2.241772\n",
      "Epoch 3, Iteration 12: Loss 2.343286\n",
      "Epoch 3, Iteration 13: Loss 2.316396\n",
      "Epoch 3, Iteration 14: Loss 2.255512\n",
      "Epoch 3, Iteration 15: Loss 2.303734\n",
      "Epoch 3, Iteration 16: Loss 2.163500\n",
      "Epoch 3, Iteration 17: Loss 2.163715\n",
      "Epoch 3, Iteration 18: Loss 2.321545\n",
      "Epoch 3, Iteration 19: Loss 2.138176\n",
      "Epoch 3, Iteration 20: Loss 2.253742\n",
      "Epoch 3, Iteration 21: Loss 2.267312\n",
      "Epoch 3, Iteration 22: Loss 2.095975\n",
      "Epoch 3, Iteration 23: Loss 2.324091\n",
      "Epoch 3, Iteration 24: Loss 2.127979\n",
      "Epoch 3, Iteration 25: Loss 2.076304\n",
      "Epoch 3, Iteration 26: Loss 2.240783\n",
      "Epoch 3, Iteration 27: Loss 2.157559\n",
      "Epoch 3, Iteration 28: Loss 2.339581\n",
      "Epoch 3, Iteration 29: Loss 2.228610\n",
      "Epoch 3, Iteration 30: Loss 2.191304\n",
      "Epoch 3, Iteration 31: Loss 2.181443\n",
      "Epoch 3, Iteration 32: Loss 2.259568\n",
      "Epoch 3, Iteration 33: Loss 2.274268\n",
      "Epoch 3, Iteration 34: Loss 2.178920\n",
      "Epoch 3, Iteration 35: Loss 2.153706\n",
      "Epoch 3, Iteration 36: Loss 2.216615\n",
      "Epoch 3, Iteration 37: Loss 2.340098\n",
      "Epoch 3, Iteration 38: Loss 2.198524\n",
      "Epoch 3, Iteration 39: Loss 2.196754\n",
      "Epoch 3, Iteration 40: Loss 2.329312\n",
      "Epoch 3, Iteration 41: Loss 2.174834\n",
      "Epoch 3, Iteration 42: Loss 1.935677\n",
      "Epoch 3, Iteration 43: Loss 2.291995\n",
      "Epoch 3, Iteration 44: Loss 2.105005\n",
      "Epoch 3, Iteration 45: Loss 2.117860\n",
      "Epoch 3, Iteration 46: Loss 2.219693\n",
      "Epoch 3, Iteration 47: Loss 2.249903\n",
      "Epoch 3, Iteration 48: Loss 2.083579\n",
      "Epoch 3, Iteration 49: Loss 2.096881\n",
      "Epoch 3, Iteration 50: Loss 2.159606\n",
      "Epoch 3, Iteration 51: Loss 2.004322\n",
      "Epoch 3, Iteration 52: Loss 2.210955\n",
      "Epoch 3, Iteration 53: Loss 1.998087\n",
      "Epoch 3, Iteration 54: Loss 2.217926\n",
      "Epoch 3, Iteration 55: Loss 2.121416\n",
      "Epoch 3, Iteration 56: Loss 2.188203\n",
      "Epoch 3, Iteration 57: Loss 2.113085\n",
      "Epoch 3, Iteration 58: Loss 2.121385\n",
      "Epoch 3, Iteration 59: Loss 2.199848\n",
      "Epoch 3, Iteration 60: Loss 2.144626\n",
      "Epoch 3, Iteration 61: Loss 1.931971\n",
      "Epoch 3, Iteration 62: Loss 2.174045\n",
      "Epoch 3, Iteration 63: Loss 2.240086\n",
      "Epoch 3, Iteration 64: Loss 2.243599\n",
      "Epoch 3, Iteration 65: Loss 2.368691\n",
      "Epoch 4, Iteration 1: Loss 2.230218\n",
      "Epoch 4, Iteration 2: Loss 2.199656\n",
      "Epoch 4, Iteration 3: Loss 2.069776\n",
      "Epoch 4, Iteration 4: Loss 2.221955\n",
      "Epoch 4, Iteration 5: Loss 2.109463\n",
      "Epoch 4, Iteration 6: Loss 2.406947\n",
      "Epoch 4, Iteration 7: Loss 2.199388\n",
      "Epoch 4, Iteration 8: Loss 2.272003\n",
      "Epoch 4, Iteration 9: Loss 2.309660\n",
      "Epoch 4, Iteration 10: Loss 1.968800\n",
      "Epoch 4, Iteration 11: Loss 2.081277\n",
      "Epoch 4, Iteration 12: Loss 2.063791\n",
      "Epoch 4, Iteration 13: Loss 2.194827\n",
      "Epoch 4, Iteration 14: Loss 2.264646\n",
      "Epoch 4, Iteration 15: Loss 2.210440\n",
      "Epoch 4, Iteration 16: Loss 2.186014\n",
      "Epoch 4, Iteration 17: Loss 2.198419\n",
      "Epoch 4, Iteration 18: Loss 2.297918\n",
      "Epoch 4, Iteration 19: Loss 2.155958\n",
      "Epoch 4, Iteration 20: Loss 2.003878\n",
      "Epoch 4, Iteration 21: Loss 2.168254\n",
      "Epoch 4, Iteration 22: Loss 2.035814\n",
      "Epoch 4, Iteration 23: Loss 1.973276\n",
      "Epoch 4, Iteration 24: Loss 2.253489\n",
      "Epoch 4, Iteration 25: Loss 2.113003\n",
      "Epoch 4, Iteration 26: Loss 2.171110\n",
      "Epoch 4, Iteration 27: Loss 2.149798\n",
      "Epoch 4, Iteration 28: Loss 2.128946\n",
      "Epoch 4, Iteration 29: Loss 1.960125\n",
      "Epoch 4, Iteration 30: Loss 2.164696\n",
      "Epoch 4, Iteration 31: Loss 2.080488\n",
      "Epoch 4, Iteration 32: Loss 2.145217\n",
      "Epoch 4, Iteration 33: Loss 2.192378\n",
      "Epoch 4, Iteration 34: Loss 2.141026\n",
      "Epoch 4, Iteration 35: Loss 2.120786\n",
      "Epoch 4, Iteration 36: Loss 2.014889\n",
      "Epoch 4, Iteration 37: Loss 2.246314\n",
      "Epoch 4, Iteration 38: Loss 2.209873\n",
      "Epoch 4, Iteration 39: Loss 1.806754\n",
      "Epoch 4, Iteration 40: Loss 2.199177\n",
      "Epoch 4, Iteration 41: Loss 2.310009\n",
      "Epoch 4, Iteration 42: Loss 2.015943\n",
      "Epoch 4, Iteration 43: Loss 2.046976\n",
      "Epoch 4, Iteration 44: Loss 1.935531\n",
      "Epoch 4, Iteration 45: Loss 2.054251\n",
      "Epoch 4, Iteration 46: Loss 2.107862\n",
      "Epoch 4, Iteration 47: Loss 2.102237\n",
      "Epoch 4, Iteration 48: Loss 2.203832\n",
      "Epoch 4, Iteration 49: Loss 2.076755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Iteration 50: Loss 2.012962\n",
      "Epoch 4, Iteration 51: Loss 2.166887\n",
      "Epoch 4, Iteration 52: Loss 2.149477\n",
      "Epoch 4, Iteration 53: Loss 2.032506\n",
      "Epoch 4, Iteration 54: Loss 2.036394\n",
      "Epoch 4, Iteration 55: Loss 2.220647\n",
      "Epoch 4, Iteration 56: Loss 2.099929\n",
      "Epoch 4, Iteration 57: Loss 1.937098\n",
      "Epoch 4, Iteration 58: Loss 2.021318\n",
      "Epoch 4, Iteration 59: Loss 2.235699\n",
      "Epoch 4, Iteration 60: Loss 1.918243\n",
      "Epoch 4, Iteration 61: Loss 2.071710\n",
      "Epoch 4, Iteration 62: Loss 2.179685\n",
      "Epoch 4, Iteration 63: Loss 2.062874\n",
      "Epoch 4, Iteration 64: Loss 2.130973\n",
      "Epoch 4, Iteration 65: Loss 2.228512\n",
      "Epoch 5, Iteration 1: Loss 2.129535\n",
      "Epoch 5, Iteration 2: Loss 2.089141\n",
      "Epoch 5, Iteration 3: Loss 2.343943\n",
      "Epoch 5, Iteration 4: Loss 2.161075\n",
      "Epoch 5, Iteration 5: Loss 2.214439\n",
      "Epoch 5, Iteration 6: Loss 1.985574\n",
      "Epoch 5, Iteration 7: Loss 2.036767\n",
      "Epoch 5, Iteration 8: Loss 2.026332\n",
      "Epoch 5, Iteration 9: Loss 2.173990\n",
      "Epoch 5, Iteration 10: Loss 2.197929\n",
      "Epoch 5, Iteration 11: Loss 2.213362\n",
      "Epoch 5, Iteration 12: Loss 2.043069\n",
      "Epoch 5, Iteration 13: Loss 1.982747\n",
      "Epoch 5, Iteration 14: Loss 2.065896\n",
      "Epoch 5, Iteration 15: Loss 2.159159\n",
      "Epoch 5, Iteration 16: Loss 1.985469\n",
      "Epoch 5, Iteration 17: Loss 2.202698\n",
      "Epoch 5, Iteration 18: Loss 2.222178\n",
      "Epoch 5, Iteration 19: Loss 2.217319\n",
      "Epoch 5, Iteration 20: Loss 2.002921\n",
      "Epoch 5, Iteration 21: Loss 1.795022\n",
      "Epoch 5, Iteration 22: Loss 2.158135\n",
      "Epoch 5, Iteration 23: Loss 1.960467\n",
      "Epoch 5, Iteration 24: Loss 2.261777\n",
      "Epoch 5, Iteration 25: Loss 2.042111\n",
      "Epoch 5, Iteration 26: Loss 2.192517\n",
      "Epoch 5, Iteration 27: Loss 2.039621\n",
      "Epoch 5, Iteration 28: Loss 1.946150\n",
      "Epoch 5, Iteration 29: Loss 2.070885\n",
      "Epoch 5, Iteration 30: Loss 2.108681\n",
      "Epoch 5, Iteration 31: Loss 2.086432\n",
      "Epoch 5, Iteration 32: Loss 2.169289\n",
      "Epoch 5, Iteration 33: Loss 1.941800\n",
      "Epoch 5, Iteration 34: Loss 2.260965\n",
      "Epoch 5, Iteration 35: Loss 2.109191\n",
      "Epoch 5, Iteration 36: Loss 2.109146\n",
      "Epoch 5, Iteration 37: Loss 1.768800\n",
      "Epoch 5, Iteration 38: Loss 1.637519\n",
      "Epoch 5, Iteration 39: Loss 2.022172\n",
      "Epoch 5, Iteration 40: Loss 2.023058\n",
      "Epoch 5, Iteration 41: Loss 2.004235\n",
      "Epoch 5, Iteration 42: Loss 2.072574\n",
      "Epoch 5, Iteration 43: Loss 2.026043\n",
      "Epoch 5, Iteration 44: Loss 2.182402\n",
      "Epoch 5, Iteration 45: Loss 1.939559\n",
      "Epoch 5, Iteration 46: Loss 2.044998\n",
      "Epoch 5, Iteration 47: Loss 2.223918\n",
      "Epoch 5, Iteration 48: Loss 2.065204\n",
      "Epoch 5, Iteration 49: Loss 2.009333\n",
      "Epoch 5, Iteration 50: Loss 1.863068\n",
      "Epoch 5, Iteration 51: Loss 1.975826\n",
      "Epoch 5, Iteration 52: Loss 1.954866\n",
      "Epoch 5, Iteration 53: Loss 2.164764\n",
      "Epoch 5, Iteration 54: Loss 2.190050\n",
      "Epoch 5, Iteration 55: Loss 2.202682\n",
      "Epoch 5, Iteration 56: Loss 1.997691\n",
      "Epoch 5, Iteration 57: Loss 2.148807\n",
      "Epoch 5, Iteration 58: Loss 1.983131\n",
      "Epoch 5, Iteration 59: Loss 2.080645\n",
      "Epoch 5, Iteration 60: Loss 2.202617\n",
      "Epoch 5, Iteration 61: Loss 1.839134\n",
      "Epoch 5, Iteration 62: Loss 2.164779\n",
      "Epoch 5, Iteration 63: Loss 2.039491\n",
      "Epoch 5, Iteration 64: Loss 2.366487\n",
      "Epoch 5, Iteration 65: Loss 1.997593\n",
      "Epoch 6, Iteration 1: Loss 2.186575\n",
      "Epoch 6, Iteration 2: Loss 2.014869\n",
      "Epoch 6, Iteration 3: Loss 2.062740\n",
      "Epoch 6, Iteration 4: Loss 1.998428\n",
      "Epoch 6, Iteration 5: Loss 2.199342\n",
      "Epoch 6, Iteration 6: Loss 1.948523\n",
      "Epoch 6, Iteration 7: Loss 2.091398\n",
      "Epoch 6, Iteration 8: Loss 2.165494\n",
      "Epoch 6, Iteration 9: Loss 2.009307\n",
      "Epoch 6, Iteration 10: Loss 2.145731\n",
      "Epoch 6, Iteration 11: Loss 2.085608\n",
      "Epoch 6, Iteration 12: Loss 2.119092\n",
      "Epoch 6, Iteration 13: Loss 2.021985\n",
      "Epoch 6, Iteration 14: Loss 2.092151\n",
      "Epoch 6, Iteration 15: Loss 1.816421\n",
      "Epoch 6, Iteration 16: Loss 1.990764\n",
      "Epoch 6, Iteration 17: Loss 2.116684\n",
      "Epoch 6, Iteration 18: Loss 1.816393\n",
      "Epoch 6, Iteration 19: Loss 2.235797\n",
      "Epoch 6, Iteration 20: Loss 2.055212\n",
      "Epoch 6, Iteration 21: Loss 2.159150\n",
      "Epoch 6, Iteration 22: Loss 2.109228\n",
      "Epoch 6, Iteration 23: Loss 2.045408\n",
      "Epoch 6, Iteration 24: Loss 1.896383\n",
      "Epoch 6, Iteration 25: Loss 2.155950\n",
      "Epoch 6, Iteration 26: Loss 1.930624\n",
      "Epoch 6, Iteration 27: Loss 2.042062\n",
      "Epoch 6, Iteration 28: Loss 1.848076\n",
      "Epoch 6, Iteration 29: Loss 1.761405\n",
      "Epoch 6, Iteration 30: Loss 1.846674\n",
      "Epoch 6, Iteration 31: Loss 1.941337\n",
      "Epoch 6, Iteration 32: Loss 1.941851\n",
      "Epoch 6, Iteration 33: Loss 2.155005\n",
      "Epoch 6, Iteration 34: Loss 2.006726\n",
      "Epoch 6, Iteration 35: Loss 1.837339\n",
      "Epoch 6, Iteration 36: Loss 2.116848\n",
      "Epoch 6, Iteration 37: Loss 2.136132\n",
      "Epoch 6, Iteration 38: Loss 2.170610\n",
      "Epoch 6, Iteration 39: Loss 1.957576\n",
      "Epoch 6, Iteration 40: Loss 2.092953\n",
      "Epoch 6, Iteration 41: Loss 2.170157\n",
      "Epoch 6, Iteration 42: Loss 2.008098\n",
      "Epoch 6, Iteration 43: Loss 2.062570\n",
      "Epoch 6, Iteration 44: Loss 2.106899\n",
      "Epoch 6, Iteration 45: Loss 1.873215\n",
      "Epoch 6, Iteration 46: Loss 2.094970\n",
      "Epoch 6, Iteration 47: Loss 1.956161\n",
      "Epoch 6, Iteration 48: Loss 2.235011\n",
      "Epoch 6, Iteration 49: Loss 2.025790\n",
      "Epoch 6, Iteration 50: Loss 1.963880\n",
      "Epoch 6, Iteration 51: Loss 2.117049\n",
      "Epoch 6, Iteration 52: Loss 1.819486\n",
      "Epoch 6, Iteration 53: Loss 2.031474\n",
      "Epoch 6, Iteration 54: Loss 2.104788\n",
      "Epoch 6, Iteration 55: Loss 2.122385\n",
      "Epoch 6, Iteration 56: Loss 2.000639\n",
      "Epoch 6, Iteration 57: Loss 2.187673\n",
      "Epoch 6, Iteration 58: Loss 2.019774\n",
      "Epoch 6, Iteration 59: Loss 2.140175\n",
      "Epoch 6, Iteration 60: Loss 2.008736\n",
      "Epoch 6, Iteration 61: Loss 1.925948\n",
      "Epoch 6, Iteration 62: Loss 1.726164\n",
      "Epoch 6, Iteration 63: Loss 2.084501\n",
      "Epoch 6, Iteration 64: Loss 1.970244\n",
      "Epoch 6, Iteration 65: Loss 2.178989\n",
      "Epoch 7, Iteration 1: Loss 1.985997\n",
      "Epoch 7, Iteration 2: Loss 1.792092\n",
      "Epoch 7, Iteration 3: Loss 1.766461\n",
      "Epoch 7, Iteration 4: Loss 1.967142\n",
      "Epoch 7, Iteration 5: Loss 2.185141\n",
      "Epoch 7, Iteration 6: Loss 2.085503\n",
      "Epoch 7, Iteration 7: Loss 1.922998\n",
      "Epoch 7, Iteration 8: Loss 1.886330\n",
      "Epoch 7, Iteration 9: Loss 1.783695\n",
      "Epoch 7, Iteration 10: Loss 2.050149\n",
      "Epoch 7, Iteration 11: Loss 2.248070\n",
      "Epoch 7, Iteration 12: Loss 2.074463\n",
      "Epoch 7, Iteration 13: Loss 2.103451\n",
      "Epoch 7, Iteration 14: Loss 2.010649\n",
      "Epoch 7, Iteration 15: Loss 1.872076\n",
      "Epoch 7, Iteration 16: Loss 2.011013\n",
      "Epoch 7, Iteration 17: Loss 2.047528\n",
      "Epoch 7, Iteration 18: Loss 2.101642\n",
      "Epoch 7, Iteration 19: Loss 2.055862\n",
      "Epoch 7, Iteration 20: Loss 1.678273\n",
      "Epoch 7, Iteration 21: Loss 1.971894\n",
      "Epoch 7, Iteration 22: Loss 1.984828\n",
      "Epoch 7, Iteration 23: Loss 2.123164\n",
      "Epoch 7, Iteration 24: Loss 1.944849\n",
      "Epoch 7, Iteration 25: Loss 2.140936\n",
      "Epoch 7, Iteration 26: Loss 1.901105\n",
      "Epoch 7, Iteration 27: Loss 2.008856\n",
      "Epoch 7, Iteration 28: Loss 2.105033\n",
      "Epoch 7, Iteration 29: Loss 1.921981\n",
      "Epoch 7, Iteration 30: Loss 2.082598\n",
      "Epoch 7, Iteration 31: Loss 1.967665\n",
      "Epoch 7, Iteration 32: Loss 1.878078\n",
      "Epoch 7, Iteration 33: Loss 2.033731\n",
      "Epoch 7, Iteration 34: Loss 2.038431\n",
      "Epoch 7, Iteration 35: Loss 1.801728\n",
      "Epoch 7, Iteration 36: Loss 1.991895\n",
      "Epoch 7, Iteration 37: Loss 1.804310\n",
      "Epoch 7, Iteration 38: Loss 1.859853\n",
      "Epoch 7, Iteration 39: Loss 2.043921\n",
      "Epoch 7, Iteration 40: Loss 2.166791\n",
      "Epoch 7, Iteration 41: Loss 2.084980\n",
      "Epoch 7, Iteration 42: Loss 1.885474\n",
      "Epoch 7, Iteration 43: Loss 1.988984\n",
      "Epoch 7, Iteration 44: Loss 1.974180\n",
      "Epoch 7, Iteration 45: Loss 1.983924\n",
      "Epoch 7, Iteration 46: Loss 1.876529\n",
      "Epoch 7, Iteration 47: Loss 2.033833\n",
      "Epoch 7, Iteration 48: Loss 2.309730\n",
      "Epoch 7, Iteration 49: Loss 2.024394\n",
      "Epoch 7, Iteration 50: Loss 2.058592\n",
      "Epoch 7, Iteration 51: Loss 1.954821\n",
      "Epoch 7, Iteration 52: Loss 2.126129\n",
      "Epoch 7, Iteration 53: Loss 2.188494\n",
      "Epoch 7, Iteration 54: Loss 2.067332\n",
      "Epoch 7, Iteration 55: Loss 2.114091\n",
      "Epoch 7, Iteration 56: Loss 2.023015\n",
      "Epoch 7, Iteration 57: Loss 2.088904\n",
      "Epoch 7, Iteration 58: Loss 2.049184\n",
      "Epoch 7, Iteration 59: Loss 1.774335\n",
      "Epoch 7, Iteration 60: Loss 1.916231\n",
      "Epoch 7, Iteration 61: Loss 1.749152\n",
      "Epoch 7, Iteration 62: Loss 1.836341\n",
      "Epoch 7, Iteration 63: Loss 2.051688\n",
      "Epoch 7, Iteration 64: Loss 2.047557\n",
      "Epoch 7, Iteration 65: Loss 1.770863\n",
      "Epoch 8, Iteration 1: Loss 2.101799\n",
      "Epoch 8, Iteration 2: Loss 2.028728\n",
      "Epoch 8, Iteration 3: Loss 1.901588\n",
      "Epoch 8, Iteration 4: Loss 1.948676\n",
      "Epoch 8, Iteration 5: Loss 2.063565\n",
      "Epoch 8, Iteration 6: Loss 2.091525\n",
      "Epoch 8, Iteration 7: Loss 1.992467\n",
      "Epoch 8, Iteration 8: Loss 1.851945\n",
      "Epoch 8, Iteration 9: Loss 2.038290\n",
      "Epoch 8, Iteration 10: Loss 2.017896\n",
      "Epoch 8, Iteration 11: Loss 2.028677\n",
      "Epoch 8, Iteration 12: Loss 1.960982\n",
      "Epoch 8, Iteration 13: Loss 2.122613\n",
      "Epoch 8, Iteration 14: Loss 1.841401\n",
      "Epoch 8, Iteration 15: Loss 1.824682\n",
      "Epoch 8, Iteration 16: Loss 1.727131\n",
      "Epoch 8, Iteration 17: Loss 1.691894\n",
      "Epoch 8, Iteration 18: Loss 2.104518\n",
      "Epoch 8, Iteration 19: Loss 1.984401\n",
      "Epoch 8, Iteration 20: Loss 2.086023\n",
      "Epoch 8, Iteration 21: Loss 2.106953\n",
      "Epoch 8, Iteration 22: Loss 1.882495\n",
      "Epoch 8, Iteration 23: Loss 1.891976\n",
      "Epoch 8, Iteration 24: Loss 1.715686\n",
      "Epoch 8, Iteration 25: Loss 2.114350\n",
      "Epoch 8, Iteration 26: Loss 2.052282\n",
      "Epoch 8, Iteration 27: Loss 1.881829\n",
      "Epoch 8, Iteration 28: Loss 1.937271\n",
      "Epoch 8, Iteration 29: Loss 1.877222\n",
      "Epoch 8, Iteration 30: Loss 1.995206\n",
      "Epoch 8, Iteration 31: Loss 1.858897\n",
      "Epoch 8, Iteration 32: Loss 1.903000\n",
      "Epoch 8, Iteration 33: Loss 2.042376\n",
      "Epoch 8, Iteration 34: Loss 1.890694\n",
      "Epoch 8, Iteration 35: Loss 1.983057\n",
      "Epoch 8, Iteration 36: Loss 1.919849\n",
      "Epoch 8, Iteration 37: Loss 2.056430\n",
      "Epoch 8, Iteration 38: Loss 2.104762\n",
      "Epoch 8, Iteration 39: Loss 1.851705\n",
      "Epoch 8, Iteration 40: Loss 1.881192\n",
      "Epoch 8, Iteration 41: Loss 1.869765\n",
      "Epoch 8, Iteration 42: Loss 2.151709\n",
      "Epoch 8, Iteration 43: Loss 2.037139\n",
      "Epoch 8, Iteration 44: Loss 1.831427\n",
      "Epoch 8, Iteration 45: Loss 2.017448\n",
      "Epoch 8, Iteration 46: Loss 2.034629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Iteration 47: Loss 1.834238\n",
      "Epoch 8, Iteration 48: Loss 2.072485\n",
      "Epoch 8, Iteration 49: Loss 2.049918\n",
      "Epoch 8, Iteration 50: Loss 1.943270\n",
      "Epoch 8, Iteration 51: Loss 1.975621\n",
      "Epoch 8, Iteration 52: Loss 1.821301\n",
      "Epoch 8, Iteration 53: Loss 2.112495\n",
      "Epoch 8, Iteration 54: Loss 1.856301\n",
      "Epoch 8, Iteration 55: Loss 2.177879\n",
      "Epoch 8, Iteration 56: Loss 1.696245\n",
      "Epoch 8, Iteration 57: Loss 1.701542\n",
      "Epoch 8, Iteration 58: Loss 1.884084\n",
      "Epoch 8, Iteration 59: Loss 1.917514\n",
      "Epoch 8, Iteration 60: Loss 1.984295\n",
      "Epoch 8, Iteration 61: Loss 1.892281\n",
      "Epoch 8, Iteration 62: Loss 2.021053\n",
      "Epoch 8, Iteration 63: Loss 1.977479\n",
      "Epoch 8, Iteration 64: Loss 1.987411\n",
      "Epoch 8, Iteration 65: Loss 2.103672\n",
      "Epoch 9, Iteration 1: Loss 2.244736\n",
      "Epoch 9, Iteration 2: Loss 1.857798\n",
      "Epoch 9, Iteration 3: Loss 2.164953\n",
      "Epoch 9, Iteration 4: Loss 1.967336\n",
      "Epoch 9, Iteration 5: Loss 1.873585\n",
      "Epoch 9, Iteration 6: Loss 2.062077\n",
      "Epoch 9, Iteration 7: Loss 1.872245\n",
      "Epoch 9, Iteration 8: Loss 1.968691\n",
      "Epoch 9, Iteration 9: Loss 2.073923\n",
      "Epoch 9, Iteration 10: Loss 1.948141\n",
      "Epoch 9, Iteration 11: Loss 1.892923\n",
      "Epoch 9, Iteration 12: Loss 2.137485\n",
      "Epoch 9, Iteration 13: Loss 1.752063\n",
      "Epoch 9, Iteration 14: Loss 2.037436\n",
      "Epoch 9, Iteration 15: Loss 1.976021\n",
      "Epoch 9, Iteration 16: Loss 1.952607\n",
      "Epoch 9, Iteration 17: Loss 1.871878\n",
      "Epoch 9, Iteration 18: Loss 1.714090\n",
      "Epoch 9, Iteration 19: Loss 1.809259\n",
      "Epoch 9, Iteration 20: Loss 1.989264\n",
      "Epoch 9, Iteration 21: Loss 2.060655\n",
      "Epoch 9, Iteration 22: Loss 1.632277\n",
      "Epoch 9, Iteration 23: Loss 1.738866\n",
      "Epoch 9, Iteration 24: Loss 1.836470\n",
      "Epoch 9, Iteration 25: Loss 1.988220\n",
      "Epoch 9, Iteration 26: Loss 1.995509\n",
      "Epoch 9, Iteration 27: Loss 1.987144\n",
      "Epoch 9, Iteration 28: Loss 1.759452\n",
      "Epoch 9, Iteration 29: Loss 1.957350\n",
      "Epoch 9, Iteration 30: Loss 1.986988\n",
      "Epoch 9, Iteration 31: Loss 1.977383\n",
      "Epoch 9, Iteration 32: Loss 1.847320\n",
      "Epoch 9, Iteration 33: Loss 1.936074\n",
      "Epoch 9, Iteration 34: Loss 1.897841\n",
      "Epoch 9, Iteration 35: Loss 1.802399\n",
      "Epoch 9, Iteration 36: Loss 2.005098\n",
      "Epoch 9, Iteration 37: Loss 1.890908\n",
      "Epoch 9, Iteration 38: Loss 2.043033\n",
      "Epoch 9, Iteration 39: Loss 2.054338\n",
      "Epoch 9, Iteration 40: Loss 1.851205\n",
      "Epoch 9, Iteration 41: Loss 1.789517\n",
      "Epoch 9, Iteration 42: Loss 2.063538\n",
      "Epoch 9, Iteration 43: Loss 1.920078\n",
      "Epoch 9, Iteration 44: Loss 1.871001\n",
      "Epoch 9, Iteration 45: Loss 1.832877\n",
      "Epoch 9, Iteration 46: Loss 2.194319\n",
      "Epoch 9, Iteration 47: Loss 1.946484\n",
      "Epoch 9, Iteration 48: Loss 1.872453\n",
      "Epoch 9, Iteration 49: Loss 1.966274\n",
      "Epoch 9, Iteration 50: Loss 1.630693\n",
      "Epoch 9, Iteration 51: Loss 1.894765\n",
      "Epoch 9, Iteration 52: Loss 1.772934\n",
      "Epoch 9, Iteration 53: Loss 1.921931\n",
      "Epoch 9, Iteration 54: Loss 2.008652\n",
      "Epoch 9, Iteration 55: Loss 2.131415\n",
      "Epoch 9, Iteration 56: Loss 1.833458\n",
      "Epoch 9, Iteration 57: Loss 2.124601\n",
      "Epoch 9, Iteration 58: Loss 2.073194\n",
      "Epoch 9, Iteration 59: Loss 1.983688\n",
      "Epoch 9, Iteration 60: Loss 1.827813\n",
      "Epoch 9, Iteration 61: Loss 2.043474\n",
      "Epoch 9, Iteration 62: Loss 1.795165\n",
      "Epoch 9, Iteration 63: Loss 1.743773\n",
      "Epoch 9, Iteration 64: Loss 2.111427\n",
      "Epoch 9, Iteration 65: Loss 1.956040\n",
      "Epoch 10, Iteration 1: Loss 1.916026\n",
      "Epoch 10, Iteration 2: Loss 1.871782\n",
      "Epoch 10, Iteration 3: Loss 2.002761\n",
      "Epoch 10, Iteration 4: Loss 2.106687\n",
      "Epoch 10, Iteration 5: Loss 1.777571\n",
      "Epoch 10, Iteration 6: Loss 1.995762\n",
      "Epoch 10, Iteration 7: Loss 1.772158\n",
      "Epoch 10, Iteration 8: Loss 2.014690\n",
      "Epoch 10, Iteration 9: Loss 2.070813\n",
      "Epoch 10, Iteration 10: Loss 2.038260\n",
      "Epoch 10, Iteration 11: Loss 1.535886\n",
      "Epoch 10, Iteration 12: Loss 2.075773\n",
      "Epoch 10, Iteration 13: Loss 2.188435\n",
      "Epoch 10, Iteration 14: Loss 1.942000\n",
      "Epoch 10, Iteration 15: Loss 1.763833\n",
      "Epoch 10, Iteration 16: Loss 1.770671\n",
      "Epoch 10, Iteration 17: Loss 1.928418\n",
      "Epoch 10, Iteration 18: Loss 1.953488\n",
      "Epoch 10, Iteration 19: Loss 1.883894\n",
      "Epoch 10, Iteration 20: Loss 2.071991\n",
      "Epoch 10, Iteration 21: Loss 1.840322\n",
      "Epoch 10, Iteration 22: Loss 1.886479\n",
      "Epoch 10, Iteration 23: Loss 1.898782\n",
      "Epoch 10, Iteration 24: Loss 1.855355\n",
      "Epoch 10, Iteration 25: Loss 1.995470\n",
      "Epoch 10, Iteration 26: Loss 1.824188\n",
      "Epoch 10, Iteration 27: Loss 1.886537\n",
      "Epoch 10, Iteration 28: Loss 1.992363\n",
      "Epoch 10, Iteration 29: Loss 2.015802\n",
      "Epoch 10, Iteration 30: Loss 1.978353\n",
      "Epoch 10, Iteration 31: Loss 1.693679\n",
      "Epoch 10, Iteration 32: Loss 1.910188\n",
      "Epoch 10, Iteration 33: Loss 2.203903\n",
      "Epoch 10, Iteration 34: Loss 1.728882\n",
      "Epoch 10, Iteration 35: Loss 2.045278\n",
      "Epoch 10, Iteration 36: Loss 1.765898\n",
      "Epoch 10, Iteration 37: Loss 1.863242\n",
      "Epoch 10, Iteration 38: Loss 1.836932\n",
      "Epoch 10, Iteration 39: Loss 2.022229\n",
      "Epoch 10, Iteration 40: Loss 2.185521\n",
      "Epoch 10, Iteration 41: Loss 2.047163\n",
      "Epoch 10, Iteration 42: Loss 1.834921\n",
      "Epoch 10, Iteration 43: Loss 2.031595\n",
      "Epoch 10, Iteration 44: Loss 1.992761\n",
      "Epoch 10, Iteration 45: Loss 1.787113\n",
      "Epoch 10, Iteration 46: Loss 2.058414\n",
      "Epoch 10, Iteration 47: Loss 2.031766\n",
      "Epoch 10, Iteration 48: Loss 1.773259\n",
      "Epoch 10, Iteration 49: Loss 1.861717\n",
      "Epoch 10, Iteration 50: Loss 1.642026\n",
      "Epoch 10, Iteration 51: Loss 1.531671\n",
      "Epoch 10, Iteration 52: Loss 1.915814\n",
      "Epoch 10, Iteration 53: Loss 1.949903\n",
      "Epoch 10, Iteration 54: Loss 1.826773\n",
      "Epoch 10, Iteration 55: Loss 1.897637\n",
      "Epoch 10, Iteration 56: Loss 1.929710\n",
      "Epoch 10, Iteration 57: Loss 1.981256\n",
      "Epoch 10, Iteration 58: Loss 1.951040\n",
      "Epoch 10, Iteration 59: Loss 1.997383\n",
      "Epoch 10, Iteration 60: Loss 1.655000\n",
      "Epoch 10, Iteration 61: Loss 1.965789\n",
      "Epoch 10, Iteration 62: Loss 1.764565\n",
      "Epoch 10, Iteration 63: Loss 1.901562\n",
      "Epoch 10, Iteration 64: Loss 1.868044\n",
      "Epoch 10, Iteration 65: Loss 1.492697\n"
     ]
    }
   ],
   "source": [
    "nsample = trainMat.shape[0]  #sample size\n",
    "bsize=30 #batch size\n",
    "niter = int(np.ceil(nsample/bsize)) #iteration per epoch\n",
    "max_epoch=10\n",
    "alpha = 0.001 #learning rate\n",
    "\n",
    "L1 = Linear(1024,200)\n",
    "Sig1 = Sigmoid()\n",
    "L2 = Linear(200,10)\n",
    "Loss = SoftmaxCrossEnt()\n",
    "Layers = [L1,Sig1,L2,Loss]\n",
    "\n",
    "for e in range(max_epoch):\n",
    "    rind = np.random.permutation(nsample) #shuffle data (this is important!)\n",
    "    trainMat = trainMat[rind]\n",
    "    trainLabels = trainLabels[rind]\n",
    "    for i in range(niter):\n",
    "        X = trainMat[i*bsize:(i+1)*bsize,:]\n",
    "        t = trainLabels[i*bsize:(i+1)*bsize]\n",
    "        h = X\n",
    "        for l,layer in enumerate(Layers):\n",
    "            if l<len(Layers)-1:\n",
    "                h = layer.forward(h)\n",
    "            else:\n",
    "                h = layer.forward(h,t) #the last layer: loss\n",
    "        L = np.average(h,axis=0)\n",
    "\n",
    "        dZ = None\n",
    "        for l,layer in enumerate(reversed(Layers)):\n",
    "            dZ = layer.backward(dZ)\n",
    "        L1.W = L1.W - alpha*L1.dW\n",
    "        L1.b = L1.b - alpha*L1.db      \n",
    "        L2.W = L2.W - alpha*L2.dW\n",
    "        L2.b = L2.b - alpha*L2.db\n",
    "\n",
    "        print(\"Epoch %d, Iteration %d: Loss %f\" % (e+1, i+1, L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
